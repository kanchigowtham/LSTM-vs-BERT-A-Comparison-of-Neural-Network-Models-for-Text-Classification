{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aUPPMSkGVmk",
        "outputId": "13eb23ad-f1c5-4895-d392-8e736b572737"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 2s 0us/step\n",
            "Epoch 1/5\n",
            "3750/3750 [==============================] - 107s 27ms/step - loss: 0.4340 - accuracy: 0.7988 - val_loss: 0.3452 - val_accuracy: 0.8644\n",
            "Epoch 2/5\n",
            "3750/3750 [==============================] - 41s 11ms/step - loss: 0.3122 - accuracy: 0.8747 - val_loss: 0.3639 - val_accuracy: 0.8448\n",
            "Epoch 3/5\n",
            "3750/3750 [==============================] - 40s 11ms/step - loss: 0.2958 - accuracy: 0.8809 - val_loss: 0.3299 - val_accuracy: 0.8692\n",
            "Epoch 4/5\n",
            "3750/3750 [==============================] - 38s 10ms/step - loss: 0.1905 - accuracy: 0.9283 - val_loss: 0.3963 - val_accuracy: 0.8648\n",
            "Epoch 5/5\n",
            "3750/3750 [==============================] - 39s 10ms/step - loss: 0.1628 - accuracy: 0.9405 - val_loss: 0.3712 - val_accuracy: 0.8680\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Load the IMDB movie review dataset\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.imdb.load_data(num_words=10000)\n",
        "\n",
        "##This code defines a function called preprocess that takes two arguments x and y.\n",
        "##\n",
        "##The first line of the function uses Keras preprocessing function pad_sequences() to pad the sequences in x to a fixed length of 500.\n",
        "##This is done to ensure that all sequences have the same length, which is necessary when training a neural network. The padded sequences are then assigned back to the variable x.\n",
        "##The second line of the function converts the y array to a NumPy array of 32-bit floating-point numbers using the astype() method. This is often done to\n",
        "##ensure that the data type of the array is compatible with other NumPy functions or machine learning libraries. The converted y array is then assigned back to the variable y.\n",
        "##Finally, the function returns the processed x and y arrays as a tuple (x, y).\n",
        "##Overall, this function preprocesses the input sequences x and their corresponding labels y in a way that is suitable for training a neural network model.\n",
        "# Preprocess the data\n",
        "# Define the maximum sequence length\n",
        "max_length = 256\n",
        "\n",
        "# Load the IMDB movie review dataset\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.imdb.load_data(num_words=10000)\n",
        "\n",
        "# Preprocess the data\n",
        "def preprocess(x, y):\n",
        "    # Pad the sequences to the maximum length\n",
        "    x = keras.preprocessing.sequence.pad_sequences(x, maxlen=max_length)\n",
        "    y = np.array(y).astype(np.float32)\n",
        "    return x, y\n",
        "\n",
        "x_train, y_train = preprocess(x_train, y_train)\n",
        "x_test, y_test = preprocess(x_test, y_test)\n",
        "\n",
        "# Build the model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Embedding(input_dim=10000, output_dim=32, input_length=max_length),\n",
        "    keras.layers.LSTM(32),\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x_train, y_train, batch_size=6, epochs=5, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(\"Test Accuracy:\", test_acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ToIk5_VcGy9E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}